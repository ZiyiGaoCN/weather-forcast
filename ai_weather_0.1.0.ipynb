{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7dd1df-6de6-4eb1-bf87-bb98ccf4e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/localdata_ssd/gaoziyi/dataset/weather_round1_train_2007, 2007-01-01T00:00:00.000000000 ~ 2007-12-31T18:00:00.000000000\n",
      "/localdata_ssd/gaoziyi/dataset/weather_round1_train_2008, 2008-01-01T00:00:00.000000000 ~ 2008-12-31T18:00:00.000000000\n",
      "/localdata_ssd/gaoziyi/dataset/weather_round1_train_2009, 2009-01-01T00:00:00.000000000 ~ 2009-12-31T18:00:00.000000000\n",
      "/localdata_ssd/gaoziyi/dataset/weather_round1_train_2010, 2010-01-01T00:00:00.000000000 ~ 2010-12-31T18:00:00.000000000\n",
      "/localdata_ssd/gaoziyi/dataset/weather_round1_train_2011, 2011-01-01T00:00:00.000000000 ~ 2011-12-31T18:00:00.000000000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unrecognized chunk manager dask - must be one of: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     ds \u001b[39m=\u001b[39m chunk_time(ds)\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m ds\n\u001b[0;32m---> 31\u001b[0m ds \u001b[39m=\u001b[39m load_dataset()\u001b[39m.\u001b[39mx\n\u001b[1;32m     33\u001b[0m num_step \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m \u001b[39m# for 5-days\u001b[39;00m\n\u001b[1;32m     34\u001b[0m shape \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mshape \u001b[39m# batch x channel x lat x lon \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     ds\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m     27\u001b[0m ds \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mconcat(ds, \u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m ds \u001b[39m=\u001b[39m chunk_time(ds)\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m ds\n",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m, in \u001b[0;36mchunk_time\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m     14\u001b[0m dims \u001b[39m=\u001b[39m {k:v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m ds\u001b[39m.\u001b[39mdims\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     15\u001b[0m dims[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 16\u001b[0m ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39;49mchunk(dims)\n\u001b[1;32m     17\u001b[0m \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/miniconda3/envs/train_weather/lib/python3.9/site-packages/xarray/core/dataset.py:2638\u001b[0m, in \u001b[0;36mDataset.chunk\u001b[0;34m(self, chunks, name_prefix, token, lock, inline_array, chunked_array_type, from_array_kwargs, **chunks_kwargs)\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[39mif\u001b[39;00m bad_dims:\n\u001b[1;32m   2634\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2635\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msome chunks keys are not dimensions on this object: \u001b[39m\u001b[39m{\u001b[39;00mbad_dims\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2636\u001b[0m     )\n\u001b[0;32m-> 2638\u001b[0m chunkmanager \u001b[39m=\u001b[39m guess_chunkmanager(chunked_array_type)\n\u001b[1;32m   2639\u001b[0m \u001b[39mif\u001b[39;00m from_array_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2640\u001b[0m     from_array_kwargs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/train_weather/lib/python3.9/site-packages/xarray/core/parallelcompat.py:93\u001b[0m, in \u001b[0;36mguess_chunkmanager\u001b[0;34m(manager)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(manager, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m chunkmanagers:\n\u001b[0;32m---> 93\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munrecognized chunk manager \u001b[39m\u001b[39m{\u001b[39;00mmanager\u001b[39m}\u001b[39;00m\u001b[39m - must be one of: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(chunkmanagers)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     \u001b[39mreturn\u001b[39;00m chunkmanagers[manager]\n\u001b[1;32m     98\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(manager, ChunkManagerEntrypoint):\n\u001b[1;32m     99\u001b[0m     \u001b[39m# already a valid ChunkManager so just pass through\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: unrecognized chunk manager dask - must be one of: []"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import torch\n",
    "torch.random.seed()\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "data_dir = '/localdata_ssd/gaoziyi/dataset' # change to you dataset dir\n",
    "\n",
    "def chunk_time(ds):\n",
    "    dims = {k:v for k, v in ds.dims.items()}\n",
    "    dims['time'] = 1\n",
    "    ds = ds.chunk(dims)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    ds = []\n",
    "    for y in range(2007, 2008):\n",
    "        data_name = os.path.join(data_dir, f'weather_round1_train_{y}')\n",
    "        x = xr.open_zarr(data_name, consolidated=True)\n",
    "        print(f'{data_name}, {x.time.values[0]} ~ {x.time.values[-1]}')\n",
    "        ds.append(x)\n",
    "    ds = xr.concat(ds, 'time')\n",
    "    ds = chunk_time(ds)\n",
    "    return ds\n",
    "\n",
    "ds = load_dataset().x\n",
    "\n",
    "num_step = 20 # for 5-days\n",
    "shape = ds.shape # batch x channel x lat x lon \n",
    "times = ds.time.values\n",
    "init_times = times[slice(1, -num_step)] \n",
    "num_data = len(init_times)\n",
    "names = list(ds.channel.values)\n",
    "test_names = names[-5:]\n",
    "\n",
    "print(f'\\n shape: {shape}')\n",
    "print('\\n times: {} ~ {}'.format(times[0], times[-1]))\n",
    "print('\\n init_times: {} ~ {}'.format(init_times[0], init_times[-1]))\n",
    "print(f'\\n names: {names}')\n",
    "print(f'\\n test_names: {test_names}\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17db486-c6a3-40d4-93e1-62256a2846c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize any variable at any time \n",
    "def visualize(time, name):\n",
    "    import cartopy.crs as ccrs\n",
    "    import matplotlib.pyplot as plt \n",
    "    import matplotlib.patches as patches\n",
    "    \n",
    "    assert name in names\n",
    "    v = ds.sel(time=time, channel=name)\n",
    "\n",
    "    \n",
    "    def plot(ds, ax, title):\n",
    "        ds.plot(\n",
    "            ax=ax, \n",
    "            x='lon', \n",
    "            y='lat', \n",
    "            transform=ccrs.PlateCarree(),  \n",
    "            # cbar_kwargs={'label': 'K'},     \n",
    "            add_colorbar=False\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        ax.coastlines()\n",
    "        gl = ax.gridlines(draw_labels=True, linewidth=0.5)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False    \n",
    "        \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "    plot(v, ax, title=f'{name.upper()}')\n",
    "    \n",
    "visualize(time='20080101-00', name='t2m')    \n",
    "visualize(time='20080101-00', name='u10')\n",
    "visualize(time='20080101-00', name='v10')\n",
    "visualize(time='20080101-00', name='msl')\n",
    "visualize(time='20080101-00', name='tp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568cf678-0156-4f75-ba7f-4644bdc4db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load seqs from dataset\n",
    "def getitem(idx):\n",
    "    assert idx < num_data\n",
    "    t = init_times[idx]\n",
    "    t1 = t - pd.Timedelta(hours=6)\n",
    "    t2 = t + pd.Timedelta(days=5) # you can reduce it for auto-regressive training \n",
    "    tid = pd.date_range(t1, t2, freq='6h')\n",
    "    \n",
    "    input = ds.sel(time=tid[:2]) # you can use subset of input, eg: only surface \n",
    "    target = ds.sel(time=tid[2:], channel=test_names)\n",
    "    \n",
    "    input = torch.from_numpy(input.values)\n",
    "    target = torch.from_numpy(target.values)\n",
    "    \n",
    "    input = torch.nan_to_num(input) # t c h w \n",
    "    target = torch.nan_to_num(target) # t c h w \n",
    "    return input, target\n",
    "\n",
    "\n",
    "def dummy_model(input, target=None):\n",
    "    if target is None:\n",
    "        output = torch.randn(20, 5, 101, 101) # step x channel x lat x lon \n",
    "    else:\n",
    "        # TODO, train your model, base on input and target,\n",
    "        # here we add noise to target produce fake output\n",
    "        output = target + torch.randn_like(target)\n",
    "    return output    \n",
    "\n",
    "\n",
    "# daily climate baseline\n",
    "climates = {\n",
    "    't2m': 3.1084048748016357,\n",
    "    'u10': 4.114771819114685,\n",
    "    'v10': 4.184110546112061,\n",
    "    'msl': 729.5839385986328,\n",
    "    'tp': 0.49046186606089276,\n",
    "}\n",
    "\n",
    "\n",
    "def compute_rmse(out, tgt):\n",
    "    rmse = torch.sqrt(((out - tgt)**2).mean())\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def run_eval(output, target):\n",
    "    '''\n",
    "        result: (batch x step x channel x lat x lon), eg: N x 20 x 5 x H x W\n",
    "        target: (batch x step x channel x lat x lon), eg: N x 20 x 5 x H x W\n",
    "    '''\n",
    "    result = {}\n",
    "    for cid, (name, clim) in enumerate(climates.items()):\n",
    "        res = []\n",
    "        for sid in range(output.shape[1]):\n",
    "            out = output[:, sid, cid]\n",
    "            tgt = target[:, sid, cid]\n",
    "            rmse = compute_rmse(out, tgt)\n",
    "            nrmse = (rmse - clim) / clim\n",
    "            res.append(nrmse)\n",
    "            \n",
    "            # normalized rmse, lower is better,\n",
    "            # 0 means equal to climate baseline, \n",
    "            # less than 0 means better than climate baseline,   \n",
    "            # -1 means perfect prediction            \n",
    "\n",
    "        score = max(0, -np.mean(res))\n",
    "        result[name] = float(score)\n",
    "\n",
    "    score = np.mean(list(result.values()))\n",
    "    result['score'] = float(score) \n",
    "    return result\n",
    "\n",
    "# Please note the data has been normalized by pre-compute mean and std, you do't need to normalized again, \n",
    "idx = np.random.randint(num_data)\n",
    "input, target = getitem(idx)\n",
    "output = dummy_model(input, target)\n",
    "print('input: {}, {} ~ {}'.format(input.shape, input.min(), input.max()))\n",
    "print('output: {}, {} ~ {}'.format(output.shape, output.min(), output.max()))\n",
    "print('target: {}, {} ~ {}'.format(target.shape, target.min(), target.max()))\n",
    "\n",
    "\n",
    "# run eval on the normalized output and target, but the online evalation will un-normalized your output to origial scale\n",
    "result = run_eval(output[None], target[None])\n",
    "score = \"\".join(f\"{k}: {v:.2f} \" for k, v in result.items()) \n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
