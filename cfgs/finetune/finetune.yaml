model:
  model_path: model.swin_unet #'dense' or 'conv', 'dense2' or 'conv2'
  model_type: SwinTransformerSys
  param: 
    param: 
    in_seq_length: 2
    out_seq_length: 1
    input_dim: 70
    output_dim: 70
    lat_dim: 161
    lon_dim: 161 # now must be same as lat_dim    # above are input and output parameters
    patch_size: 2
    hidden_dim: 192
    window_size: 10

data: 
  data_path : /local_ssd/gaoziyi/finetune_ckpt_2 #the folder of 3 npy file
  # npy_name: ('data1.npy', 'data2.npy', 'data3.npy') # order: target_npy, input1.npy, input2.npy, if None, write (a.npy, None, None)
  # npy_len: (7304 , -1, -1) #3-tuple, set -1 if the npy not exist 
  # 14612 for 2007-2016
  preload_to_memory: False
  argument: False
  # train_range: [2007,2008]
  # val_range: [2008,2009]

finetune: 
  # original_dir: ../dataset
  generated_dir: /local_ssd/gaoziyi/finetune_ckpt_2/dataset
  checkpoint_dir: /local_ssd/gaoziyi/finetune_ckpt_2/checkpoint

train:   
  optimizer:
    name: Adam
    learning_rate: 0.02
    weight_decay: 1e-5
    scheduler: 
      name: NoamLR
      hidden_dim: 192
      warmup_steps: 200
  n_epochs: 3  
  ckpt_dir: checkpoint
  device: cuda:6
  autoregressive: True

  dataloader:
    num_workers: 8
    batch_size: 64
    prefetch_factor: 16

logger: #default wandb
   project: weather-finetune
   name: swin-AR-finetune

seed: 114514

